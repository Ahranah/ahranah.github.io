---
layout: post
title: "[금융전략을 위한 머신러닝] NLP"
date: 2024-10-10 02:38:26 +0900
categories: [Data Science, Machine Learning]
---

# 자연어 처리: 파이썬 패키지

1. NLTK

가장 유명한 nlp 파이썬 라이브러리. 학습된 영어용 토크나이저 punkt 를 다운해 사용한다. 

2. TextBlob

NLTK 위에 빌드되는 테스트 처리 단순화 라이브러리

3. spaCy

단일 목적에 하나의 알고리즘만 제시하여 선택할 필요 없이 생산성에 집중할 수 있다. 

# 이론 및 개념

텍스트 데이터를 전처리하고 텍스트를 통계적 추론 알고리즘에 입력하기 전에 예측 특성으로 표현

{% include figure.liquid loading="eager" path="assets/img/posts/2024-10-10-금융전략을-위한-머신러닝-nlp/Screenshot 2024-10-10 at 2.07.22 AM.png" class="img-fluid rounded z-depth-1" %}

 

# 전처리

1. 토큰화

텍스트를 토큰이라고 하는 의미 있는 세그먼트로 분할하는 작업.

> 세그먼트:  문장의 구성요소 (단어, 구두점, 숫자 등)

- NLTK Punkt

 

2. 불용어 제거

모델링에 값을 거의 제공하지 않는 매우 일반적인 단어를 어휘에서 제외

''' from nltk.corpus import stopwords '''

 

3. 형태소 분석

변형된(파생된) 단어를 어간, 어기 또는 어근 형식으로 줄인다.

> Stems, Stemming -> Stem

''' from nltk.stem.snowball import SnowballStemmer '''  

 

4. 기본형식화

형태소 분석의 변형: 형태소는 종종 존재하지 않는 단어를 생성하는 반면 기본형은 실제 단어

 

5. 품사 태깅 part-of-speech(PoS)

문법 범주(동사, 명사 등)에 토큰 할당 과정 : 문장 범위에서 단어가 사용되는 방식을 나타내는 언어 신호 제공

''' TextBlob().tags '''

6. 명명 개체 인식 named entity recognition (NER) (선택적 단계)

텍스트에서 명명된 개체를 미리 정의된 범주(사람, 조직, 위치 등)에 따라 분류 

- 명명된 개체를 시각화하면 개발 속도, 코드 디버깅에 유용하다.

 

## spaCy: 모든 전처리를 한 번에 완료

nlp 호출 시 텍스트 토큰화로 문서 객체 생성 -> 파이프라인을 거쳐 -> 문서화

{% include figure.liquid loading="eager" path="assets/img/posts/2024-10-10-금융전략을-위한-머신러닝-nlp/Screenshot 2024-10-10 at 2.16.31 AM.png" class="img-fluid rounded z-depth-1" %}

 

선택적 전처리 단계

- 파싱 (종속성 구문 분석)

문장의 단어가 서로 어떻게 관련되는지 이해하기 위해 문장에 구문 구조 할당

- 상호 참조 해결

동일 개체를 나타내는 토큰 연결: 그/그녀로 지칭

 

# 알고리즘에 전처리 정보 전달: 토큰의 특성화

전처리된 정보는 사람이 사용할 수 있는 == 컴퓨터에서 처리할 수 없는 구조화되지 않는 형식으로 저장되는 경우가 많다. 따라ㅏ서 토큰을 예측 특성으로 변환해야 한다. 원시 텍스트를 벡터 공간에 임베딩하는데 모델을 사용한다. 

1. 단어 모음 - 단어 수

텍스트에서 발생한 모든 단어를 버킷에 배치한다. 이 접근 방식은 단어 모음 모델이라고 하는데 문장 구조에 대한 모든 정보가 손실 되기 때문이다.

{% include figure.liquid loading="eager" path="assets/img/posts/2024-10-10-금융전략을-위한-머신러닝-nlp/Screenshot 2024-10-10 at 2.22.03 AM.png" class="img-fluid rounded z-depth-1" %}

 

행렬의 값은 나타내는 토큰의 인스턴스 수를 나타낸다. 

 

2. 단어 빈도 - 역문서 빈도(TF-IDF)

- 역문서 빈도: 문서 전체에 많이 나타난 단어를 축소한다. 

단어 모음(단어 수)에 비해 더 흥미로운 단어를 강조하는 단어 빈도 점수이다. 각 어휘에 대해 가중치를 출력한다. 

 

3. 단어 임베딩

벡터 표현으로 단어와 문서를 나타낸다. 임베딩에서 단어는 벡터로 표현되며 이때 단어의 위치는 텍스트에서 학습된다. 단어를 사용할 때 단어를 둘러싼 단어를 기반으로 한다. 학습된 벡터 공간에서 단어 위치를 임베딩이라고 한다. 

 

### 사전 학습된 모델: spaCy

다양한 수준의 단어, 문장, 문서에서 텍스트를 벡터로 만드는 기본 표현을 제공한다. 

- 기본 벡터 표현은 단어의 다차원적 의미 표현을 생성하는 단어 임베딩 모델에서 비롯된다. 

모델을 불러온 다음 텍스트를 처리하는데 처리된 각 토큰(단어) 는 .vector 속성을 사용해 직접 접근할 수 있다. 

 

# 추론

머신러닝(지도, 비지도, 강화 학습)에서 데이터 유형과 비즈니스 문제에 따라 알맞은 방법을 택한다. 

- 지도: 나이브 베이즈 Naive Bayes
> 간단한 가정으로 합리적 정확도

- 비지도: Latent Semantic Analysis(LSA)
> 용어와 관련된 잠재 개념 집합을 생성해 문서 집합과 포함된 단어의 관계 조사, LDA보다 정교한 접근

- Latent Dirichlet Allocation(LDA): 문서를 유한한 주제의 혼합으로 모델링 -> 주제 모델링

 

## [지도] Naive Bayes: 확률적 분류기

주어진 샘플의 범주 예측에 사용, 특성의 독립을 가정해 Bayes 정리 적용

 

## [비지도] LDA

주제 모델링에 사용: 인간이 해석할 수 있는 의미 있는 주제 생성 + 새 문서에 주제 할당 후 확장 가능

각 주제에 대해 일련의 단어를 선택해 문서 생성 -> 알고리즘이 리버스 엔지니어링하여 문서에서 주제 탐색